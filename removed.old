REMOVED FROM main.py ------------------------------------------------------------------------
# def get_parser1():  # unused
#     # parameter priority: command line > config > default
#     parser = argparse.ArgumentParser(
#         description='Spatial Temporal Graph Convolution Network')
#     parser.add_argument(
#         '--work-dir',
#         default='./work_dir/temp',
#         help='the work folder for storing results')

#     parser.add_argument('-model_saved_name', default='')
#     parser.add_argument(
#         '--config',
#         default=r'config\\smarthome-cross-subject\\train_joint_new.yaml',
#         help='path to the configuration file')

#     # processor
#     parser.add_argument(
#         '--phase', default='train', help='must be train or test')
#     parser.add_argument(
#         '--save-score',
#         type=str2bool,
#         default=False,
#         help='if ture, the classification score will be stored')

#     # visulize and debug
#     parser.add_argument(
#         '--seed', type=int, default=1, help='random seed for pytorch')
#     parser.add_argument(
#         '--log-interval',
#         type=int,
#         default=100,
#         help='the interval for printing messages (#iteration)')
#     parser.add_argument(
#         '--save-interval',
#         type=int,
#         default=2,
#         help='the interval for storing models (#iteration)')
#     parser.add_argument(
#         '--eval-interval',
#         type=int,
#         default=5,
#         help='the interval for evaluating models (#iteration)')
#     parser.add_argument(
#         '--print-log',
#         type=str2bool,
#         default=True,
#         help='print logging or not')
#     parser.add_argument(
#         '--show-topk',
#         type=int,
#         default=[1, 5],
#         nargs='+',
#         help='which Top K accuracy will be shown')

#     # feeder
#     parser.add_argument(
#         '--feeder', default='feeder.feeder', help='data loader will be used')
#     parser.add_argument(
#         '--num-worker',
#         type=int,
#         default=32,
#         help='the number of worker for data loader')
#     parser.add_argument(
#         '--train-feeder-args',
#         default=dict(),
#         help='the arguments of data loader for training')
#     parser.add_argument(
#         '--test-feeder-args',
#         default=dict(),
#         help='the arguments of data loader for test')

#     # model
#     parser.add_argument('--model', default=None, help='the model will be used')
#     parser.add_argument(
#         '--model-args',
#         type=dict,
#         default=dict(),
#         help='the arguments of model')
#     parser.add_argument(
#         '--weights',
#         default=None,
#         help='the weights for network initialization')
#     parser.add_argument(
#         '--ignore-weights',
#         type=str,
#         default=[],
#         nargs='+',
#         help='the name of weights which will be ignored in the initialization')

#     # optim
#     parser.add_argument(
#         '--base-lr', type=float, default=0.01, help='initial learning rate')
#     parser.add_argument(
#         '--step',
#         type=int,
#         default=[20, 40, 60],
#         nargs='+',
#         help='the epoch where optimizer reduce the learning rate')
#     parser.add_argument(
#         '--device',
#         type=int,
#         default=0,
#         nargs='+',
#         help='the indexes of GPUs for training or testing')
#     parser.add_argument('--optimizer', default='SGD', help='type of optimizer')
#     parser.add_argument(
#         '--nesterov', type=str2bool, default=False, help='use nesterov or not')
#     parser.add_argument(
#         '--batch-size', type=int, default=256, help='training batch size')
#     parser.add_argument(
#         '--test-batch-size', type=int, default=256, help='test batch size')
#     parser.add_argument(
#         '--start-epoch',
#         type=int,
#         default=0,
#         help='start training from which epoch')
#     parser.add_argument(
#         '--num-epoch',
#         type=int,
#         default=80,
#         help='stop training in which epoch')
#     parser.add_argument(
#         '--weight-decay',
#         type=float,
#         default=0.0005,
#         help='weight decay for optimizer')
#     parser.add_argument('--only_train_part', default=False)
#     parser.add_argument('--only_train_epoch', default=0)
#     parser.add_argument('--warm_up_epoch', default=0)
#     return parser
-----------------------------------------------------------------------------
from processor.py

def load_model(self):
        output_device = self.arg.device[0] if type(self.arg.device) is list else self.arg.device
        self.output_device = output_device
        Model = import_class(self.arg.model)
        shutil.copy2(inspect.getfile(Model), self.arg.work_dir)
        #print(Model)
        self.model = Model(**self.arg.model_args).cuda(output_device)
        #print(self.model)
        self.loss = nn.CrossEntropyLoss().cuda(output_device)

        if self.arg.weights:
            self.global_step = int(self.arg.weights[:-3].split('-')[-1])
            self.print_log('Load weights from {}.'.format(self.arg.weights))
            if '.pkl' in self.arg.weights:
                with open(self.arg.weights, 'r') as f:
                    weights = pickle.load(f)
            else:
                weights = torch.load(self.arg.weights)

            weights = OrderedDict(
                [[k.split('module.')[-1],
                  v.cuda(output_device)] for k, v in weights.items()])

            keys = list(weights.keys())
            for w in self.arg.ignore_weights:
                for key in keys:
                    if w in key:
                        if weights.pop(key, None) is not None:
                            self.print_log('Successfully Remove Weights: {}.'.format(key))
                        else:
                            self.print_log('Can Not Remove Weights: {}.'.format(key))

            try:
                self.model.load_state_dict(weights)
            except:
                state = self.model.state_dict()
                diff = list(set(state.keys()).difference(set(weights.keys())))
                print('Can not find these weights:')
                for d in diff:
                    print('  ' + d)
                state.update(weights)
                self.model.load_state_dict(state)
        
        self.model.fuse_bin = True
        self.model.fuse_layer()
        self.model.cuda()
        for p in self.model.parameters():
            p.requires_grad = False
        self.model.fuse_fc.weight.requires_grad = True
        self.model.fuse_fc.bias.requires_grad = True
        if type(self.arg.device) is list:
            if len(self.arg.device) > 1:
                self.model = nn.DataParallel(
                    self.model,
                    device_ids=self.arg.device,
                    output_device=output_device)
        return self.model